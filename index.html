<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="None" />
      <link rel="shortcut icon" href="img/favicon.ico" />
    <title>FASTEL Documentation</title>
    <link rel="stylesheet" href="css/theme.css" />
    <link rel="stylesheet" href="css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="assets/_mkdocstrings.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Home";
        var mkdocs_page_input_path = "index.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/yaml.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/languages/rust.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href="." class="icon icon-home"> FASTEL Documentation
        </a>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href=".">Home</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#introduction-to-differentiable-tree-ensembles">Introduction to differentiable tree ensembles</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#differentiable-decision-trees">Differentiable decision trees</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#differentiable-tree-ensembles">Differentiable tree ensembles</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#predictions">Predictions</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#conclusion">Conclusion</a>
    </li>
        </ul>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="fastel/">FASTEL</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="tutorial/">Tutorial</a>
                </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href=".">FASTEL Documentation</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Home</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="flexible-modeling-and-multitask-learning-using-differentiable-tree-ensembles">Flexible Modeling and Multitask Learning using Differentiable Tree Ensembles</h1>
<p><strong> Authors: Shibal Ibrahim, Hussein Hazimeh, Rahul Mazumder </strong></p>
<p>This site provides an introduction to FASTEL, a new toolkit for learning differentiable tree ensembles <a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539412">(2022, Ibrahim, Hazimeh and Mazumder)</a>. An introduction to differentiable tree ensembles can be found below. To dive in, a code tutorial can be found in the <a href="tutorial/">Tutorial Section</a>. </p>
<p>Our contributions, which can be summarized as follows, are:</p>
<ul>
<li>Proposition of a flexible framework for training differentiable tree ensembles with seamless support for new loss functions.</li>
<li>Introduction of a novel, tensor-based formulation for differentiable tree ensembles that allows for efficient training on GPUs.</li>
<li>Extension of differentiable tree ensembles to multi-task learning settings by introducing a new regularizer that allows for soft parameter sharing across tasks.</li>
<li>Introduction of FASTEL — a new toolkit (based on Tensorflow 2.0) for learning differentiable tree ensembles</li>
</ul>
<p>To have more details about our countributions, please visit <a href="fastel/">Fastel</a>. </p>
<h2 id="introduction-to-differentiable-tree-ensembles">Introduction to differentiable tree ensembles</h2>
<h3 id="differentiable-decision-trees">Differentiable decision trees</h3>
<p>Classical decision trees perform hard sample routing, i.e., a sample is routed to exactly one child at every splitting node. Hard sample routing introduces discontinuities in the loss function, making trees unamenable to continuous optimization. Therefore, trees are usually built in a greedy fashion. 
To tackle that problem, we introduce the concept of soft tree, which can be extended to soft tree ensembles. 
A soft tree is a variant of a decision tree that performs soft routing, where every internal node can route the sample to the left and right simultaneously, with different proportions. This routing mechanism makes soft trees differentiable, so learning can be done using gradient-based methods.</p>
<figure align="middle">
  <img src="img/index/classicvssofttree.png" width="700" />
  <figcaption> <span style="font-size:0.7em;">
  Comparison of soft tree vs. classic tree routing methods. On the classic tree a sample is routed to exactly one child at every splitting node, on the other side, a sample is routed to the left and right simultaneously, with different proportions, given a logistic function S </span>
  </span>  

  </figcaption>
</figure>

<p>Internal (split) nodes in a differentiable tree perform soft routing, where a sample is routed left and right with different proportions. Although the sample routing is formulated with a probabilistic model, the final prediction of the tree <span class="arithmatex">\(f\)</span> is a deterministic function as it assumes an expectation over the leaf predictions. Classical decision trees are modeled with either axis-aligned splits or hyperplane (a.k.a. oblique) splits. Soft trees are based on hyperplane splits, where the routing decisions rely on a linear combination of the features. Particularly, each internal node <span class="arithmatex">\(i \in \mathcal{I}^j\)</span> is associated with a trainable weight vector <span class="arithmatex">\(w_i^j \in \mathbb{R}^p\)</span> that defines the node’s hyperplane split. Given a sample <span class="arithmatex">\(x \in \mathbb{R}^p\)</span> , the probability that internal node i routes <span class="arithmatex">\(x\)</span> to the left is defined by <span class="arithmatex">\(S(w_i^j ·x)\)</span>,where <span class="arithmatex">\(S : \mathbb{R} → [0, 1]\)</span> is an activation function. Popular choices for <span class="arithmatex">\(S\)</span> include logistic function and smooth-step function (for conditional computation as in classical trees with oblique splits). </p>
<h3 id="differentiable-tree-ensembles">Differentiable tree ensembles</h3>
<p>We learn an ensemble of m differentiable trees. Let  <span class="arithmatex">\(f^j\)</span> be the <span class="arithmatex">\(j\)</span> th tree in the ensemble. For easier exposition, we consider a single-task regression.
For an input feature-vector <span class="arithmatex">\(x \in \mathbb{R}^p\)</span> , we learn an additive model with the output being sum over outputs of all the trees:</p>
<div class="arithmatex">\[\begin{equation}
f(x) = \sum_{j=1}^m f^j(x)
\end{equation}\]</div>
<p>The output, <span class="arithmatex">\(f(x)\)</span>, is a vector in <span class="arithmatex">\(\mathbb{R}^k\)</span> containing raw predictions. For multiclass classification, mapping from raw predictions to <span class="arithmatex">\(Y\)</span> is done by applying a softmax function on the vector <span class="arithmatex">\(f (x )\)</span> and returning the class with the highest probability.</p>
<h3 id="predictions">Predictions</h3>
<p>As with classical decision trees, we can assume that each leaf stores a weight vector <span class="arithmatex">\(o_l^j \in \mathbb{R}^k\)</span> (learned during training). Therefore, for a sample <span class="arithmatex">\(x \in \mathbb{R}^p\)</span> , the prediction of the tree can be defined as the expected value of the leaf outputs, i.e.,</p>
<div class="arithmatex">\[\begin{equation}
f^j(x) = \sum_{l \in L} P^j(\{x → l\}) o_l^j
\end{equation}\]</div>
<p>where <span class="arithmatex">\(L\)</span> is the set of leaves in the tree</p>
<figure align="middle">
  <img src="img/index/results.png" width="700" />
  <figcaption> <span style="font-size:0.7em;"> </span>
  </span>  

  </figcaption>
</figure>

<h3 id="conclusion">Conclusion</h3>
<p>End-to-end learning with differentiable tree ensembles appears to have several advantages. </p>
<ol>
<li>Training is easy to set up in public deep learning frameworks. Differentiable tree ensembles allow for flexibility in loss functions without the need for specialized algorithms. For example, mixture likelihoods can be easily implemented in Tensorflow Probability, which allows for handling zero-inflated data. Similarly, multi-task loss objectives can also be handled. </li>
<li>With a careful implementation, the tree ensemble can be trained efficiently on GPUs — this is not possible with earlier toolkits such as TEL.</li>
<li>Differentiable trees can lead to more expressive and compact ensembles. This can have important implications for interpretability, latency and storage requirements during inference.</li>
</ol>
<p>This is the framework implemented in the FASTEL package. To see it in action, the tutorial can be found <a href="tutorial/">here</a>. </p>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="fastel/" class="btn btn-neutral float-right" title="FASTEL">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
    
      <span><a href="fastel/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '.';</script>
    <script src="js/theme_extra.js" defer></script>
    <script src="js/theme.js" defer></script>
      <script src="javascripts/config.js" defer></script>
      <script src="https://polyfill.io/v3/polyfill.min.js?features=es6" defer></script>
      <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>

<!--
MkDocs version : 1.3.1
Build Date UTC : 2022-09-13 20:57:22.710395+00:00
-->
